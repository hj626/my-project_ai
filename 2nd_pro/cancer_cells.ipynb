{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "373fc809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"ê¸°ì¡´ì˜ í•­ì•” ì¹˜ë£Œê°€ í‰ê· ì ì¸ í™˜ìë¥¼ ìœ„í•œ ì ‘ê·¼ ë°©ì‹ì´ì—ˆë‹¤ë©´,\n",
    "# ë³¸ í”„ë¡œì íŠ¸ëŠ” í™˜ìì˜ ìœ ì „ì ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì•”ì„¸í¬ì˜ ê³ ìœ í•œ íŠ¹ì„±ì„ íŒŒì•…í•˜ê³ \n",
    "# ê°œì¸ ë§ì¶¤í˜• ì¹˜ë£Œ ì „ëµì„ ì„¤ê³„í•˜ëŠ” ë° ê¸°ì—¬í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.\"\n",
    "\n",
    "# AIë¥¼ í†µí•œ íì•” ì•”ì„¸í¬ ì‹ í•­ì› ë°œêµ´ ë° ì•”ì‚´ì(ë©´ì—­ì„¸í¬) ì„¤ê³„.\n",
    "# ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ Output(ê²°ê³¼ê°’)ì´ ì™œ \"ì´ ë‹¨ë°±ì§ˆì´ ì‹ í•­ì›ì¼ í™•ë¥ \n",
    "\n",
    "# \"ì‹ í•­ì›(Neoantigen) /\"ì•”ì„¸í¬ê°€ ê°€ì§„ ê³ ìœ í•œ ìœ„ì¥ ì‹¤íŒ¨ì˜ í”ì \"\n",
    "# ì•”ì„¸í¬ê°€ ëŠì„ì—†ì´ ëŒì—°ë³€ì´ë¥¼ ì¼ìœ¼í‚¤ëŠ” ê³¼ì •ì—ì„œ ë§Œë“¤ì–´ì§„ ì™„ì „íˆ ìƒˆë¡œìš´(Neo) ë‹¨ë°±ì§ˆ ì¡°ê°(Antigen)\"ë°œêµ´ \n",
    "\n",
    "# ì•”ì‚´ì: ì•”ì„¸í¬ì˜ íŠ¹ì • ë‹¨ë°±ì§ˆ(ì‹ í•­ì›)ì„ ì‹ë³„í•˜ì—¬ ì •ë°€í•˜ê²Œ ê³µê²©í•˜ê³  íŒŒê´´í•˜ëŠ” ë©´ì—­ ì„¸í¬(Tì„¸í¬)\n",
    "# ì•”ì„¸í¬ëŠ” ê³„ì† ë³€í•´ì„œ ë©´ì—­ì„¸í¬ê°€ ëª» ì•Œì•„ì±”. \n",
    "# AIì˜ ì—­í• : í™˜ìì˜ ìœ ì „ì ì„œì—´(í…ìŠ¤íŠ¸ ë°ì´í„°)ì„ ë¶„ì„í•´ì„œ,\n",
    "# ë©´ì—­ì„¸í¬ê°€ 'ì 'ìœ¼ë¡œ ì¸ì‹í•  ìˆ˜ ìˆëŠ” ìµœì ì˜ ë‹¨ë°±ì§ˆ ì¡°ê°(ì‹ í•­ì›)ì„ AIê°€ ë””ìì¸\n",
    "# ì•”ë°±ì‹  ì„¤ê³„ë„ ì—­í• .\n",
    "\n",
    "# 1D-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cefcda52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\code\\.venv\\lib\\site-packages\\google\\api_core\\_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.6) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3037b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í°íŠ¸ì§€ì •\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "\n",
    "# ë§ˆì´ë„ˆìŠ¤ ë¶€í˜¸ ê¹¨ì§ ì§€ì •\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "\n",
    "# íŒŒì¼ì´ ë„ˆë¬´ ì»¤ì„œ csv íŒŒì¼ ì½ì–´ì˜¤ëŠ”ë° ë„ˆë¬´ ì‹œê°„ì´ ê±¸ë¦¼ - > íŒŒì¼ ë³€í™˜í•´ì„œ ì‹œê°„ ë‹¨ì¶•í•˜ê¸° ìœ„í•´ ì´ë¶€ë¶„ ì¶”ê°€ ì§„í–‰\n",
    "# 1. ì²˜ìŒ í•œ ë²ˆë§Œ ì‹¤í–‰: CSVë¥¼ ë¶ˆëŸ¬ì™€ì„œ í•„ìš”í•œ ê²ƒë§Œ ì±™ê¸´ ë’¤ 'íŒŒì¼“'ìœ¼ë¡œ ì €ì¥\n",
    "# df = pd.read_csv('dataset/mhc_ligand_full.csv', low_memory=False)\n",
    "\n",
    "# Parquet í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ì••ì¶•ë¥ ì´ ì—„ì²­ë‚©ë‹ˆë‹¤)\n",
    "# ë§Œì•½ ì—ëŸ¬ê°€ ë‚˜ë©´ !pip install pyarrow .\n",
    "# df.to_parquet('dataset/mhc_data.parquet')\n",
    "# print(\"ì¶•í•˜í•©ë‹ˆë‹¤! ì´ì œ mhc_data.parquet íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ë°ì´í„°ê°€ ë„ˆë¬´ ì»¤ì„œ ì»´ì—ì„œ ì½ì§€ ëª»í•˜ëŠ” ê²½ìš° ì•„ë˜ ë°©ë²•ìœ¼ë¡œ ì§„í–‰\n",
    "# csv_file = 'dataset/mhc_ligand_full.csv'\n",
    "# parquet_file = 'dataset/mhc_data.parquet'\n",
    "# chunk_size = 100000  # í•œ ë²ˆì— 10ë§Œ í–‰ì”© ì½ê¸° (ë©”ëª¨ë¦¬ ìƒí™©ì— ë”°ë¼ ì¡°ì ˆ)\n",
    "\n",
    "# # 1. Parquet ì €ì¥ì„ ìœ„í•œ ì²« ë£¨í”„\n",
    "# first_chunk = True\n",
    "# for chunk in pd.read_csv(csv_file, low_memory=False, chunksize=chunk_size):\n",
    "#     if first_chunk:\n",
    "#         # ì²« ë²ˆì§¸ ì²­í¬ëŠ” íŒŒì¼ì„ ìƒˆë¡œ ìƒì„±\n",
    "#         chunk.to_parquet(parquet_file, engine='pyarrow', index=False)\n",
    "#         first_chunk = False\n",
    "#     else:\n",
    "#         # ì´í›„ ì²­í¬ëŠ” ê¸°ì¡´ íŒŒì¼ì— ì¶”ê°€ (ë‹¨, fastparquet ì—”ì§„ ê¶Œì¥ í˜¹ì€ append ë°©ì‹ ê³ ë ¤)\n",
    "#         # ì¼ë°˜ì ì¸ to_parquetëŠ” ë®ì–´ì“°ê¸°ê°€ ê¸°ë³¸ì´ë¯€ë¡œ ì•„ë˜ì˜ 'ë°©ë²• 2'ë¥¼ ë” ì¶”ì²œí•©ë‹ˆë‹¤.\n",
    "#         pass\n",
    "\n",
    "# print(\"ë³€í™˜ ì™„ë£Œ!\")\n",
    "\n",
    "# 2. ë°ì´í„° ë¡œë“œ\n",
    "df = pd.read_parquet('dataset/mhc_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d12dbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ğŸ“‚ ì „ì²´ ì»¬ëŸ¼ëª… ëª©ë¡\n",
      "--------------------------------------------------\n",
      "1. Assay ID\n",
      "2. Reference\n",
      "3. Reference.1\n",
      "4. Reference.2\n",
      "5. Reference.3\n",
      "6. Reference.4\n",
      "7. Reference.5\n",
      "8. Reference.6\n",
      "9. Reference.7\n",
      "10. Epitope\n",
      "11. Epitope.1\n",
      "12. Epitope.2\n",
      "13. Epitope.3\n",
      "14. Epitope.4\n",
      "15. Epitope.5\n",
      "16. Epitope.6\n",
      "17. Epitope.7\n",
      "18. Epitope.8\n",
      "19. Epitope.9\n",
      "20. Epitope.10\n",
      "21. Epitope.11\n",
      "22. Epitope.12\n",
      "23. Epitope.13\n",
      "24. Epitope.14\n",
      "25. Epitope.15\n",
      "26. Epitope.16\n",
      "27. Epitope.17\n",
      "28. Epitope.18\n",
      "29. Related Object\n",
      "30. Related Object.1\n",
      "31. Related Object.2\n",
      "32. Related Object.3\n",
      "33. Related Object.4\n",
      "34. Related Object.5\n",
      "35. Related Object.6\n",
      "36. Related Object.7\n",
      "37. Related Object.8\n",
      "38. Related Object.9\n",
      "39. Related Object.10\n",
      "40. Related Object.11\n",
      "41. Related Object.12\n",
      "42. Related Object.13\n",
      "43. Related Object.14\n",
      "44. Host\n",
      "45. Host.1\n",
      "46. Host.2\n",
      "47. Host.3\n",
      "48. Host.4\n",
      "49. Host.5\n",
      "50. Host.6\n",
      "51. in vivo Process\n",
      "52. in vivo Process.1\n",
      "53. in vivo Process.2\n",
      "54. in vivo Process.3\n",
      "55. in vivo Antigen\n",
      "56. in vivo Antigen.1\n",
      "57. in vivo Antigen.2\n",
      "58. in vivo Antigen.3\n",
      "59. in vivo Antigen.4\n",
      "60. in vivo Antigen.5\n",
      "61. in vivo Antigen.6\n",
      "62. in vivo Antigen.7\n",
      "63. in vivo Antigen.8\n",
      "64. in vivo Antigen.9\n",
      "65. in vivo Antigen.10\n",
      "66. in vivo Antigen.11\n",
      "67. in vivo Antigen.12\n",
      "68. in vivo Antigen.13\n",
      "69. in vivo Antigen.14\n",
      "70. in vivo Antigen.15\n",
      "71. in vivo Antigen.16\n",
      "72. in vivo Antigen.17\n",
      "73. In vitro Process\n",
      "74. In vitro Process.1\n",
      "75. In vitro Process.2\n",
      "76. In vitro Process.3\n",
      "77. In vitro Process.4\n",
      "78. In vitro Process.5\n",
      "79. In vitro Process.6\n",
      "80. In vitro Process.7\n",
      "81. In vitro Process.8\n",
      "82. In vitro Process.9\n",
      "83. In vitro Process.10\n",
      "84. In vitro Process.11\n",
      "85. In vitro Process.12\n",
      "86. In vitro Process.13\n",
      "87. In vitro Process.14\n",
      "88. In vitro Process.15\n",
      "89. Antigen Processing\n",
      "90. Assay\n",
      "91. Assay.1\n",
      "92. Assay.2\n",
      "93. Assay.3\n",
      "94. Assay.4\n",
      "95. Assay.5\n",
      "96. Assay.6\n",
      "97. Assay.7\n",
      "98. Assay.8\n",
      "99. Assay.9\n",
      "100. Assay.10\n",
      "101. Assay.11\n",
      "102. Assay.12\n",
      "103. Antigen Presenting Cell\n",
      "104. Antigen Presenting Cell.1\n",
      "105. Antigen Presenting Cell.2\n",
      "106. Antigen Presenting Cell.3\n",
      "107. Antigen Presenting Cell.4\n",
      "108. MHC Restriction\n",
      "109. MHC Restriction.1\n",
      "110. MHC Restriction.2\n",
      "111. MHC Restriction.3\n",
      "112. MHC Restriction.4\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤ì œ ì»¬ëŸ¼ëª… ì¶œë ¥\n",
    "print(\"=\"*50)\n",
    "print(\"ğŸ“‚ ì „ì²´ ì»¬ëŸ¼ëª… ëª©ë¡\")\n",
    "print(\"-\" * 50)\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(f\"{i+1}. {col}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "df = pd.read_parquet('dataset/mhc_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f7df4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Assay ID                          Reference  \\\n",
      "0                       IEDB IRI                           IEDB IRI   \n",
      "1   http://www.iedb.org/assay/26  http://www.iedb.org/reference/274   \n",
      "2  http://www.iedb.org/assay/115  http://www.iedb.org/reference/299   \n",
      "3  http://www.iedb.org/assay/143  http://www.iedb.org/reference/304   \n",
      "4  http://www.iedb.org/assay/144  http://www.iedb.org/reference/304   \n",
      "\n",
      "  Reference.1 Reference.2    Reference.3  \\\n",
      "0        Type        PMID  Submission ID   \n",
      "1  Literature    15448372           None   \n",
      "2  Literature    15140958           None   \n",
      "3  Literature    15102821           None   \n",
      "4  Literature    15102821           None   \n",
      "\n",
      "                                         Reference.4   Reference.5  \\\n",
      "0                                            Authors       Journal   \n",
      "1  Yi-Hsiang Huang; Mi-Hua Tao; Cheng-Po Hu; Wan-...   J Gen Virol   \n",
      "2  Yue-Dan Wang; Wan-Yee Fion Sin; Guo-Bing Xu; H...       J Virol   \n",
      "3  Alberto Diaz-QuiÃ±onez; Natalia Martin-Orozco; ...  Infect Immun   \n",
      "4  Alberto Diaz-QuiÃ±onez; Natalia Martin-Orozco; ...  Infect Immun   \n",
      "\n",
      "  Reference.6                                        Reference.7  \\\n",
      "0        Date                                              Title   \n",
      "1        2004  Identification of novel HLA-A*0201-restricted ...   \n",
      "2        2004  T-cell epitopes in severe acute respiratory sy...   \n",
      "3        2004  Two Salmonella OmpC K(b)-restricted epitopes f...   \n",
      "4        2004  Two Salmonella OmpC K(b)-restricted epitopes f...   \n",
      "\n",
      "                             Epitope  ... Antigen Presenting Cell  \\\n",
      "0                        Epitope IRI  ...           Source Tissue   \n",
      "1  http://www.iedb.org/epitope/31803  ...                    None   \n",
      "2  http://www.iedb.org/epitope/36724  ...                    None   \n",
      "3  http://www.iedb.org/epitope/66114  ...                    None   \n",
      "4  http://www.iedb.org/epitope/55063  ...                    None   \n",
      "\n",
      "  Antigen Presenting Cell.1 Antigen Presenting Cell.2  \\\n",
      "0         Source Tissue IRI                      Name   \n",
      "1                      None                      None   \n",
      "2                      None                      None   \n",
      "3                      None                      None   \n",
      "4                      None                      None   \n",
      "\n",
      "  Antigen Presenting Cell.3 Antigen Presenting Cell.4 MHC Restriction  \\\n",
      "0                       IRI         Culture Condition            Name   \n",
      "1                      None                      None     HLA-A*02:01   \n",
      "2                      None                      None          HLA-A2   \n",
      "3                      None                      None           H2-Kb   \n",
      "4                      None                      None           H2-Kb   \n",
      "\n",
      "                            MHC Restriction.1 MHC Restriction.2  \\\n",
      "0                                         IRI     Evidence Code   \n",
      "1  http://purl.obolibrary.org/obo/MRO_0001007              None   \n",
      "2  http://purl.obolibrary.org/obo/MRO_0001530              None   \n",
      "3  http://purl.obolibrary.org/obo/MRO_0000991              None   \n",
      "4  http://purl.obolibrary.org/obo/MRO_0000991              None   \n",
      "\n",
      "  MHC Restriction.3 MHC Restriction.4  \n",
      "0      Evidence IRI             Class  \n",
      "1              None                 I  \n",
      "2              None                 I  \n",
      "3              None                 I  \n",
      "4              None                 I  \n",
      "\n",
      "[5 rows x 112 columns]\n"
     ]
    }
   ],
   "source": [
    "# ì»¬ëŸ¼ì°¾ê¸°(ì»¬ëŸ¼ëª…ì´ ì´ìƒí•´ì„œ ëŒ€í‘œ 5ê°œ ë°ì´í„°ë¡œ ì¶”ê°€ í™•ì¸)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4217587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ ê²°ê³¼(Label) ë²ˆí˜¸: [94], ë‚´ìš©: Positive\n",
      "âœ… ê· í˜• ì¡íŒ ë°ì´í„° í™•ë³´: Positive 6ê±´ / Negative 6ê±´\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\code\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 181.78it/s]0<00:00, 15.50it/s, Describe variable: Hydrophobic_Score]\n",
      "Summarize dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 30.61it/s, Completed]                          \n",
      "Generate report structure: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.87s/it]\n",
      "Render HTML: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.19it/s]\n",
      "Export report to file: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 333.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "âœ… ìµœì¢… 9-mer íì•” ë°ì´í„° í™•ë³´: 10ê±´\n",
      "--------------------------------------------------\n",
      "       Sequence                  Label\n",
      "6539  GLACHQLCA  Positive-Intermediate\n",
      "5140  YMNGTMSQV          Positive-High\n",
      "5132  LLMGTLGIV          Positive-High\n",
      "6536  FLWGPRALV  Positive-Intermediate\n",
      "6617  YLSGANLNL           Positive-Low\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------------------------------------------------\n",
    "# âœ… [ìµœì¢… ìˆ˜ì •] KeyError ë°©ì§€ìš© ìœ„ì¹˜ ê¸°ë°˜ í•„í„°ë§\n",
    "# ---------------------------------------------------------\n",
    "# ì»¬ëŸ¼ ì´ë¦„ ëŒ€ì‹  'ìœ„ì¹˜(8ë²ˆì§¸)'ë¥¼ ì‚¬ìš©í•˜ì—¬ í‚¤ì›Œë“œ ê²€ì‚¬\n",
    "# .iloc[:, 8]ì€ ëª¨ë“  í–‰ì˜ 8ë²ˆì§¸ ì»¬ëŸ¼ ë°ì´í„°ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
    "is_lung_cancer = df.iloc[:, 8].str.contains('Lung|Adenocarcinoma|NSCLC|Cancer', case=False, na=False)\n",
    "\n",
    "# ì´ì œ ì¸ë±ìŠ¤ ì˜¤ë¥˜ ì—†ì´ íì•” ë°ì´í„°ë§Œ ê³¨ë¼ëƒ…ë‹ˆë‹¤.\n",
    "df_lung = df[is_lung_cancer].copy()\n",
    "\n",
    "\n",
    "# ë”± 5ì¤„ë§Œ ê°€ì ¸ì™€ì„œ ëª¨ë“  ì¹¸ì— ë­ê°€ ë“¤ì–´ìˆëŠ”ì§€ ë²ˆí˜¸ë³„ë¡œ ë´…ë‹ˆë‹¤.\n",
    "# ì—¬ê¸°ì„œ 'Positive'ë‚˜ 'Negative'ë¼ëŠ” ë‹¨ì–´ê°€ ìˆëŠ” ë²ˆí˜¸ë¥¼ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤. ë°ì´í„°ê°€ ë„ˆë¬´ ë§ì•„ì„œ ê²°ê³¼ë¥¼ ì°¾ëŠ” í•¨ìˆ˜\n",
    "test_row = df_lung.iloc[0] \n",
    "for i, val in enumerate(test_row):\n",
    "    if 'Positive' in str(val) or 'Negative' in str(val):\n",
    "        print(f\"ğŸ¯ ê²°ê³¼(Label) ë²ˆí˜¸: [{i}], ë‚´ìš©: {val}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# [ë‹¨ê³„ 1] í™•ë³´ëœ íì•” ë°ì´í„°ì—ì„œ í•„ìš”í•œ ì¹¸(ì„œì—´, ê²°ê³¼) ì¶”ì¶œ\n",
    "# ---------------------------------------------------------# [ìˆ˜ì •ëœ Cell 6 ë¡œì§]\n",
    "# 1. íì•” ë°ì´í„° ì¤‘ Positiveì™€ Negativeë¥¼ ê°ê° ì¶”ì¶œ\n",
    "df_pos = df_lung[df_lung.iloc[:, 94].str.contains('Positive', case=False, na=False)].copy()\n",
    "df_neg = df_lung[df_lung.iloc[:, 94].str.contains('Negative', case=False, na=False)].copy()\n",
    "\n",
    "# 2. ë°ì´í„° ë¶ˆê· í˜• í•´ê²° (Negative ë°ì´í„°ê°€ ì ë‹¤ë©´ ì „ì²´ ë°ì´í„°ì—ì„œ ì •ìƒ ìƒ˜í”Œì„ ë” ê°€ì ¸ì™€ì•¼ í•¨)\n",
    "# ì—¬ê¸°ì„œëŠ” í•™ìŠµì˜ ì§ˆì„ ìœ„í•´ 1:1 ë¹„ìœ¨ë¡œ ë§ì¶¤ ìƒ˜í”Œë§ì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "sample_size = min(len(df_pos), len(df_neg))\n",
    "df_pos_sampled = df_pos.sample(n=sample_size, random_state=42)\n",
    "df_neg_sampled = df_neg.sample(n=sample_size, random_state=42)\n",
    "\n",
    "# 3. ë‘ ë°ì´í„°ë¥¼ í•©ì³ì„œ ìµœì¢… í•™ìŠµì…‹ êµ¬ì„±\n",
    "df_final = pd.concat([df_pos_sampled, df_neg_sampled])\n",
    "df_final = df_final.iloc[:, [11, 94]] # ì„œì—´ê³¼ ë¼ë²¨ë§Œ ì¶”ì¶œ\n",
    "df_final.columns = ['Sequence', 'Label']\n",
    "\n",
    "# 9ê¸€ì í•„í„°ë§\n",
    "df_final = df_final[df_final['Sequence'].str.len() == 9].dropna()\n",
    "print(f\"âœ… ê· í˜• ì¡íŒ ë°ì´í„° í™•ë³´: Positive {sample_size}ê±´ / Negative {sample_size}ê±´\")\n",
    "\n",
    "# ê¸°ì¡´ df_finalì„ ë³µì‚¬í•´ì„œ ë¶„ì„ìš© ë³€ìˆ˜ë“¤ì„ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "df_report = df_final.copy()\n",
    "\n",
    "# 1. ì„œì—´ì˜ ê¸¸ì´ (ëª¨ë‘ 9ê² ì§€ë§Œ í†µê³„ì—ëŠ” ì¡í™ë‹ˆë‹¤)\n",
    "df_report['Seq_Length'] = df_report['Sequence'].str.len()\n",
    "\n",
    "# 2. íŠ¹ì • ì•„ë¯¸ë…¸ì‚°ì˜ í¬í•¨ ì—¬ë¶€ (ì˜ˆ: ì•”ì„¸í¬ì™€ ê´€ë ¨ ê¹Šì€ 'L', 'V' ë“±)\n",
    "df_report['Has_Leucine(L)'] = df_report['Sequence'].str.contains('L').astype(int)\n",
    "df_report['Has_Valine(V)'] = df_report['Sequence'].str.contains('V').astype(int)\n",
    "\n",
    "# 3. ì„œì—´ì˜ ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ ì•„ë¯¸ë…¸ì‚° (ìœ„ì¹˜ë³„ íŠ¹ì„± íŒŒì•…ìš©)\n",
    "df_report['First_AA'] = df_report['Sequence'].str[0]\n",
    "df_report['Last_AA'] = df_report['Sequence'].str[-1]\n",
    "\n",
    "# 4. ì•„ë¯¸ë…¸ì‚°ì˜ ì†Œìˆ˜ì„±(Hydrophobicity) ëŒ€ëµì  ë¶„ë¥˜ (ê°„ë‹¨ ì˜ˆì‹œ)\n",
    "# ì„œì—´ì— íŠ¹ì • ë¬¸ìê°€ ë§ìœ¼ë©´ 1, ì•„ë‹ˆë©´ 0 ì‹ìœ¼ë¡œ íŠ¹ì§• ì¶”ì¶œ\n",
    "df_report['Hydrophobic_Score'] = df_report['Sequence'].apply(lambda x: sum(1 for aa in x if aa in 'AILMFPWV'))\n",
    "\n",
    "# ì´ì œ ë³€ìˆ˜ê°€ ëŠ˜ì–´ë‚œ ë°ì´í„°ë¡œ ë¦¬í¬íŠ¸ ìƒì„±!\n",
    "from ydata_profiling import ProfileReport\n",
    "profile = ProfileReport(df_report, title=\"íì•” ì‹ í•­ì› ì •ë°€ ë¶„ì„ ë¦¬í¬íŠ¸\")\n",
    "profile.to_file(\"lung_cancer_rich_report.html\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"âœ… ìµœì¢… 9-mer íì•” ë°ì´í„° í™•ë³´: {len(df_final)}ê±´\")\n",
    "print(\"-\" * 50)\n",
    "print(df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "961dca52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\human-24\\AppData\\Local\\Temp\\ipykernel_15540\\1817969079.py:12: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "C:\\Users\\human-24\\AppData\\Local\\Temp\\ipykernel_15540\\1817969079.py:19: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# 1. ì•„ë¯¸ë…¸ì‚° ë¹ˆë„ íˆíŠ¸ë§µ\n",
    "def draw_heatmap(df):\n",
    "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    heatmap_data = np.zeros((20, 9))\n",
    "    for seq in df['Sequence']:\n",
    "        for i, aa in enumerate(seq):\n",
    "            if aa in amino_acids:\n",
    "                heatmap_data[amino_acids.index(aa), i] += 1\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(heatmap_data, xticklabels=range(1, 10), yticklabels=list(amino_acids), cmap='YlGnBu')\n",
    "    plt.title('ì‹ í•­ì› ì„œì—´ ìœ„ì¹˜ë³„ ì•„ë¯¸ë…¸ì‚° ë¶„í¬ (Heatmap)')\n",
    "    plt.show()\n",
    "\n",
    "# 2. ì •ë‹µ ë ˆì´ë¸” ë¶„í¬ (íˆìŠ¤í† ê·¸ë¨/ë°” ì°¨íŠ¸)\n",
    "def draw_label_dist(df):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.countplot(x='Label', data=df)\n",
    "    plt.title('ë©´ì—­ ë°˜ì‘ ì •ë‹µ(Label) ë¶„í¬')\n",
    "    plt.show()\n",
    "\n",
    "# ì‹¤í–‰\n",
    "draw_heatmap(df_final)\n",
    "draw_label_dist(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47c894c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: (8, 9, 20)\n",
      "âœ… ì‹ í•­ì›(Positive) ìƒ˜í”Œ ë¹„ì¤‘: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\code\\.venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 1. ì•„ë¯¸ë…¸ì‚° ì¸ì½”ë”© í•¨ìˆ˜ (ë…¸íŠ¸ë¶ ë¶„ì„ ê²°ê³¼ ë°˜ì˜)\n",
    "def encode_sequence(seq):\n",
    "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY' # 20ê°œ í‘œì¤€ ìˆœì„œ\n",
    "    aa_to_int = {aa: i for i, aa in enumerate(amino_acids)}\n",
    "    matrix = np.zeros((9, 20))\n",
    "    for i, aa in enumerate(seq.upper()):\n",
    "        if aa in aa_to_int:\n",
    "            matrix[i, aa_to_int[aa]] = 1\n",
    "    return matrix\n",
    "\n",
    "# 1-2. ë¦¬ìŠ¤íŠ¸ ì „ì²´ ë³€í™˜ í•¨ìˆ˜\n",
    "def encode_all_sequences(sequences):\n",
    "    encoded_list = [encode_sequence(s) for s in sequences]\n",
    "    return np.array(encoded_list)\n",
    "\n",
    "# 2. ëª¨ë¸ ìƒì„± í•¨ìˆ˜ ì •ì˜ (ê°œì„ ëœ 1D-CNN êµ¬ì¡°)\n",
    "def build_improved_model():\n",
    "    model = models.Sequential([\n",
    "        # ì²« ë²ˆì§¸ ì¸µ: ì„œì—´ì˜ ì§€ì—­ì  íŠ¹ì§• í¬ì°©\n",
    "        layers.Conv1D(64, kernel_size=3, padding='same', activation='relu', input_shape=(9, 20)),\n",
    "        layers.BatchNormalization(), # í•™ìŠµ ì•ˆì •í™”\n",
    "        \n",
    "        # ë‘ ë²ˆì§¸ ì¸µ: ë” ë„“ì€ íŒ¨í„´ í¬ì°©\n",
    "        layers.Conv1D(128, kernel_size=2, padding='same', activation='relu'),\n",
    "        layers.GlobalMaxPooling1D(), # ìœ„ì¹˜ ë¬´ê´€ íŠ¹ì§• ì¶”ì¶œ\n",
    "        \n",
    "        # ì˜ì‚¬ê²°ì • ì¸µ\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.3), # ê³¼ì í•© ë°©ì§€\n",
    "        layers.Dense(1, activation='sigmoid') # í™•ë¥  ì¶œë ¥\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 3. ë°ì´í„° ì¤€ë¹„ ë° ëª¨ë¸ ìƒì„± ì‹¤í–‰\n",
    "# X, y ë°ì´í„° ìƒì„±\n",
    "X = encode_all_sequences(df_final['Sequence'].values)\n",
    "y = (df_final['Label'].str.contains('Positive', case=False)).astype(int).values\n",
    "\n",
    "# ë°ì´í„°ì…‹ ë¶„ë¦¬ (80% í•™ìŠµ, 20% í…ŒìŠ¤íŠ¸)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ëª¨ë¸ ìƒì„± (ì´ì œ í•¨ìˆ˜ê°€ ìœ„ì—ì„œ ì •ì˜ë˜ì—ˆìœ¼ë¯€ë¡œ ì—ëŸ¬ê°€ ë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤)\n",
    "model = build_improved_model()\n",
    "\n",
    "print(f\"âœ… í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {X_train.shape}\")\n",
    "print(f\"âœ… ì‹ í•­ì›(Positive) ìƒ˜í”Œ ë¹„ì¤‘: {y.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0949c4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ê°œì„ ëœ AI ëª¨ë¸ë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "Epoch 1/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.5000 - loss: 1.4774 - precision: 0.5000 - recall: 1.0000 - val_accuracy: 0.5000 - val_loss: 0.7117 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 2/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.5000 - loss: 1.1762 - precision: 0.5000 - recall: 1.0000 - val_accuracy: 0.5000 - val_loss: 0.7068 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 3/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.5000 - loss: 0.9041 - precision: 0.5000 - recall: 0.7500 - val_accuracy: 0.5000 - val_loss: 0.7038 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 4/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.7500 - loss: 0.6736 - precision: 0.6667 - recall: 1.0000 - val_accuracy: 0.5000 - val_loss: 0.7030 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 5/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.7500 - loss: 0.7991 - precision: 0.6667 - recall: 1.0000 - val_accuracy: 0.5000 - val_loss: 0.7036 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 6/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.8750 - loss: 0.4969 - precision: 0.8000 - recall: 1.0000 - val_accuracy: 0.5000 - val_loss: 0.7047 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 7/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.7500 - loss: 0.4899 - precision: 0.7500 - recall: 0.7500 - val_accuracy: 0.5000 - val_loss: 0.7057 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 8/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.8750 - loss: 0.3702 - precision: 0.8000 - recall: 1.0000 - val_accuracy: 0.5000 - val_loss: 0.7064 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 9/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.8750 - loss: 0.3541 - precision: 0.8000 - recall: 1.0000 - val_accuracy: 0.5000 - val_loss: 0.7069 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 10/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.8750 - loss: 0.2935 - precision: 0.8000 - recall: 1.0000 - val_accuracy: 0.5000 - val_loss: 0.7072 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 11/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8750 - loss: 0.2892 - precision: 0.8000 - recall: 1.0000 - val_accuracy: 0.5000 - val_loss: 0.7077 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 12/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8750 - loss: 0.5052 - precision: 0.8000 - recall: 1.0000 - val_accuracy: 0.5000 - val_loss: 0.7085 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 13/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.8750 - loss: 0.2273 - precision: 0.8000 - recall: 1.0000 - val_accuracy: 0.5000 - val_loss: 0.7096 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 14/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.8750 - loss: 0.2670 - precision: 0.8000 - recall: 1.0000 - val_accuracy: 0.5000 - val_loss: 0.7108 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 15/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.8750 - loss: 0.3594 - precision: 0.8000 - recall: 1.0000 - val_accuracy: 0.5000 - val_loss: 0.7118 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 16/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8750 - loss: 0.3261 - precision: 0.8000 - recall: 1.0000 - val_accuracy: 0.5000 - val_loss: 0.7129 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 17/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.8750 - loss: 0.2213 - precision: 0.8000 - recall: 1.0000 - val_accuracy: 0.5000 - val_loss: 0.7140 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 18/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8750 - loss: 0.4033 - precision: 0.8000 - recall: 1.0000 - val_accuracy: 0.5000 - val_loss: 0.7147 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 19/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8750 - loss: 0.2723 - precision: 0.8000 - recall: 1.0000 - val_accuracy: 0.5000 - val_loss: 0.7154 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 20/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.8750 - loss: 0.3080 - precision: 0.8000 - recall: 1.0000 - val_accuracy: 0.5000 - val_loss: 0.7161 - val_precision: 0.5000 - val_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# âœ… [9ë²ˆ ì…€ ìˆ˜ì •] ê°œì„ ëœ ëª¨ë¸ë¡œ í•™ìŠµ ì§„í–‰\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# 1. 9ë²ˆ ì…€ ìƒë‹¨ì˜ ëª¨ë¸ ì¬ì •ì˜(Sequential...) ë¶€ë¶„ì„ ì‚­ì œí•©ë‹ˆë‹¤.\n",
    "# 2. ëŒ€ì‹  8ë²ˆ ì…€ì—ì„œ ì´ë¯¸ ìƒì„±ëœ 'model' ê°ì²´ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ëª¨ë¸ ì„¤ì • (í•™ìŠµ ì§€í‘œ ì¶”ê°€)\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "# 3. ëª¨ë¸ í•™ìŠµ ì‹œì‘ \n",
    "print(\"ğŸš€ ê°œì„ ëœ AI ëª¨ë¸ë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "# ì‹¤ì œ ì‹ í•­ì›ì„ ë” ì˜ ë§íˆê¸° ìœ„í•´ ê°€ì¤‘ì¹˜(class_weight)ë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
    "# Positive(1) ë°ì´í„°ë¥¼ ë” ì—„ê²©í•˜ê²Œ ë°°ìš°ë„ë¡ 2.5ë°° ê°€ì¤‘ì¹˜ë¥¼ ë‘¡ë‹ˆë‹¤.\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=20,           # í•™ìŠµ íšŸìˆ˜ë¥¼ ì¡°ê¸ˆ ë” ëŠ˜ë ¤ ìˆ™ë ¨ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.\n",
    "                    batch_size=32, \n",
    "                    validation_data=(X_test, y_test),\n",
    "                    class_weight={0: 1.0, 1: 2.5}) # ì‹¤ì œ í•­ì›ì„ ë†“ì¹˜ì§€ ì•Šê²Œ ê°•ì¡°\n",
    "\n",
    "# 4. ê²°ê³¼ ì‹œê°í™” ì½”ë“œëŠ” ë™ì¼í•˜ê²Œ ìœ ì§€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3724e360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.7161 - precision: 0.5000 - recall: 1.0000\n",
      "ğŸ“Š ìµœì¢… í…ŒìŠ¤íŠ¸ ì†ì‹¤(Loss): 0.7161\n",
      "ğŸ¯ ìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„(Accuracy): 50.00%\n",
      "âš–ï¸ ì •ë°€ë„(Precision): 50.00%  <- 'ì•”'ì´ë¼ê³  í•œ ê²ƒ ì¤‘ ì§„ì§œ ì•”ì¸ ë¹„ìœ¨\n",
      "ğŸ“ˆ ì¬í˜„ìœ¨(Recall): 100.00%  <- ì‹¤ì œ ì•” ì„œì—´ì„ ë†“ì¹˜ì§€ ì•Šê³  ì°¾ì•„ë‚¸ ë¹„ìœ¨\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\n",
      "--- ğŸ”¬ ì‹ í•­ì› ì˜ˆì¸¡ ìˆ˜í–‰ ê²°ê³¼ (ìƒ˜í”Œ) ---\n",
      "ì„œì—´ ìƒ˜í”Œ 1ë²ˆ -> ì˜ˆì¸¡ ê²°ê³¼: Positive (í™•ë¥ : 59.52%)\n",
      "ì„œì—´ ìƒ˜í”Œ 2ë²ˆ -> ì˜ˆì¸¡ ê²°ê³¼: Positive (í™•ë¥ : 58.99%)\n"
     ]
    }
   ],
   "source": [
    "# 1. ëª¨ë¸ í‰ê°€ (ì§€í‘œê°€ ì—¬ëŸ¬ ê°œì´ë¯€ë¡œ ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ìŠµë‹ˆë‹¤)\n",
    "evaluation_results = model.evaluate(X_test, y_test)\n",
    "\n",
    "# ëª¨ë¸ ì»´íŒŒì¼ ì‹œ ì„¤ì •í•œ ìˆœì„œëŒ€ë¡œ ê°’ì´ ë“¤ì–´ì˜µë‹ˆë‹¤: [Loss, Accuracy, Precision, Recall]\n",
    "loss = evaluation_results[0]\n",
    "accuracy = evaluation_results[1]\n",
    "precision = evaluation_results[2]\n",
    "recall = evaluation_results[3]\n",
    "\n",
    "print(f\"ğŸ“Š ìµœì¢… í…ŒìŠ¤íŠ¸ ì†ì‹¤(Loss): {loss:.4f}\")\n",
    "print(f\"ğŸ¯ ìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„(Accuracy): {accuracy*100:.2f}%\")\n",
    "print(f\"âš–ï¸ ì •ë°€ë„(Precision): {precision*100:.2f}%  <- 'ì•”'ì´ë¼ê³  í•œ ê²ƒ ì¤‘ ì§„ì§œ ì•”ì¸ ë¹„ìœ¨\")\n",
    "print(f\"ğŸ“ˆ ì¬í˜„ìœ¨(Recall): {recall*100:.2f}%  <- ì‹¤ì œ ì•” ì„œì—´ì„ ë†“ì¹˜ì§€ ì•Šê³  ì°¾ì•„ë‚¸ ë¹„ìœ¨\")\n",
    "\n",
    "# 2. ìƒ˜í”Œ ë°ì´í„° ì˜ˆì¸¡ ìˆ˜í–‰ (ì´ ë¶€ë¶„ì€ ë™ì¼í•©ë‹ˆë‹¤)\n",
    "samples = X_test[:5]\n",
    "predictions = model.predict(samples)\n",
    "\n",
    "print(\"\\n--- ğŸ”¬ ì‹ í•­ì› ì˜ˆì¸¡ ìˆ˜í–‰ ê²°ê³¼ (ìƒ˜í”Œ) ---\")\n",
    "\n",
    "# predictionsì— ë“¤ì–´ìˆëŠ” ì‹¤ì œ ê°œìˆ˜ë§Œí¼ë§Œ ë°˜ë³µí•©ë‹ˆë‹¤.\n",
    "# ë§Œì•½ 5ê°œë³´ë‹¤ ë§ì„ ë•Œ ë”± 5ê°œë§Œ ë³´ê³  ì‹¶ë‹¤ë©´ min(len(predictions), 5)ë¥¼ ì“°ì„¸ìš”.\n",
    "num_samples = len(predictions) \n",
    "\n",
    "for i in range(num_samples):\n",
    "    # predictions[i]ê°€ ë°°ì—´ í˜•íƒœì¸ ê²½ìš°ì™€ ë‹¨ì¼ ê°’ì¸ ê²½ìš°ë¥¼ ëª¨ë‘ ê³ ë ¤\n",
    "    prob = predictions[i][0] if hasattr(predictions[i], \"__len__\") else predictions[i]\n",
    "    \n",
    "    result = \"Positive\" if prob > 0.5 else \"Negative\"\n",
    "    probability = prob * 100\n",
    "    print(f\"ì„œì—´ ìƒ˜í”Œ {i+1}ë²ˆ -> ì˜ˆì¸¡ ê²°ê³¼: {result} (í™•ë¥ : {probability:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2855ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 144.97it/s]0<00:00, 14.59it/s, Describe variable: Hydrophobic_Score]\n",
      "Summarize dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:00<00:00, 34.13it/s, Completed]                          \n",
      "Generate report structure: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.92s/it]\n",
      "Render HTML: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.68it/s]\n",
      "Export report to file: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ¨ ë°ì´í„° ë¶„ì„ ë¦¬í¬íŠ¸ê°€ 'lung_cancer_FINAL_report.html'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# 1. ë¦¬í¬íŠ¸ ìƒì„± (ë°˜ë“œì‹œ df_reportë¥¼ ë„£ì–´ì•¼ 8ê°œ ë³€ìˆ˜ê°€ ë³´ì…ë‹ˆë‹¤!)\n",
    "profile = ProfileReport(df_report, \n",
    "                        title=\"íì•” ì‹ í•­ì› ì •ë°€ ë¶„ì„ ë¦¬í¬íŠ¸ (8ê°œ ë³€ìˆ˜)\", \n",
    "                        explorative=True,\n",
    "                        minimal=False)\n",
    "\n",
    "# 2. HTML íŒŒì¼ë¡œ ì €ì¥\n",
    "profile.to_file(\"lung_cancer_FINAL_report.html\")\n",
    "\n",
    "# 3. ì™„ë£Œ ë©”ì‹œì§€ (íŒŒì¼ ì´ë¦„ ì¼ì¹˜ì‹œí‚¤ê¸°)\n",
    "print(\"âœ¨ ë°ì´í„° ë¶„ì„ ë¦¬í¬íŠ¸ê°€ 'lung_cancer_FINAL_report.html'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c77008f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ¨ ëª¨ë¸ì´ 'lung_cancer_model.keras'ë¡œ ì•ˆì „í•˜ê²Œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# ê¸°ì¡´ .h5 ëŒ€ì‹  ìµœì‹  í‘œì¤€ì¸ .kerasë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "model.save(\"lung_cancer_model.keras\")\n",
    "\n",
    "print(\"âœ¨ ëª¨ë¸ì´ 'lung_cancer_model.keras'ë¡œ ì•ˆì „í•˜ê²Œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
