{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a29ca6e1",
   "metadata": {},
   "source": [
    "í˜„ì¬ êµ¬í˜„: ì†Œì†¡ ìœ í˜• ë¶„ë¥˜ë§Œ (5ê°œ ì¹´í…Œê³ ë¦¬)\n",
    "- í—Œë²•, í˜•ì‚¬ì†Œì†¡, í–‰ì •ì†Œì†¡, ë¯¼ì‚¬/ê°€ì‚¬ì†Œì†¡, ê¸°íƒ€\n",
    "\n",
    "ì—¬ê¸°ì— ì¶”ê°€ ê¸°ëŠ¥:\n",
    "1. ìŠ¹ì†Œìœ¨ ì˜ˆì¸¡\n",
    "2. í˜•ëŸ‰/ë²Œê¸ˆ ì˜ˆì¸¡ ã„´\n",
    "3. ìœ„í—˜ë„ ë¶„ì„\n",
    "4. ê´€ë ¨ íŒë¡€ ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48274447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„í¬íŠ¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "print(\"í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5b2475e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.\n",
      "   í•™ìŠµ ë°ì´í„°: 48,308ê±´\n",
      "   í…ŒìŠ¤íŠ¸ ë°ì´í„°: 5,435ê±´\n",
      "\n",
      "ğŸ”„ ê¸°íƒ€ì™€ í—Œë²• ì œì™¸\n",
      "\n",
      "âœ… í•„í„°ë§ ì™„ë£Œ!\n",
      "   í•™ìŠµ ë°ì´í„°: 48,308ê±´\n",
      "   í…ŒìŠ¤íŠ¸ ë°ì´í„°: 5,435ê±´\n",
      "\n",
      "[í•„í„°ë§ í›„ ì†Œì†¡ ìœ í˜• ë¶„í¬]\n",
      "case_type\n",
      "í˜•ì‚¬ì†Œì†¡       37831\n",
      "í–‰ì •ì†Œì†¡        9433\n",
      "ë¯¼ì‚¬/ê°€ì‚¬ì†Œì†¡     1044\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ë¡œë“œ\n",
    "try:\n",
    "    train_df = pd.read_pickle(\"../pkl_file/pkl/train_filtered.pkl\")\n",
    "    test_df = pd.read_pickle(\"../pkl_file/pkl/test_filtered.pkl\")\n",
    "    \n",
    "    print(\"âœ… ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.\")\n",
    "    print(f\"   í•™ìŠµ ë°ì´í„°: {len(train_df):,}ê±´\")\n",
    "    print(f\"   í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df):,}ê±´\")\n",
    "    \n",
    "    # â­ ì¶”ê°€: ê¸°íƒ€ì™€ í—Œë²• ì œì™¸\n",
    "    print(\"\\nğŸ”„ ê¸°íƒ€ì™€ í—Œë²• ì œì™¸\")\n",
    "    train_df = train_df[~train_df['case_type'].isin(['ê¸°íƒ€', 'í—Œë²•'])].copy()\n",
    "    test_df = test_df[~test_df['case_type'].isin(['ê¸°íƒ€', 'í—Œë²•'])].copy()\n",
    "    \n",
    "    print(f\"\\nâœ… í•„í„°ë§ ì™„ë£Œ!\")\n",
    "    print(f\"   í•™ìŠµ ë°ì´í„°: {len(train_df):,}ê±´\")\n",
    "    print(f\"   í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df):,}ê±´\")\n",
    "    print(\"\\n[í•„í„°ë§ í›„ ì†Œì†¡ ìœ í˜• ë¶„í¬]\")\n",
    "    print(train_df['case_type'].value_counts())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"   machine_legal.ipynbì—ì„œ ë°ì´í„°ë¥¼ ë¨¼ì € ì €ì¥í•´ì£¼ì„¸ìš”.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e766330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… íŠ¹ì„± ì¶”ì¶œ í•¨ìˆ˜ 4ê°œ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ì…€3. íŠ¹ì„± ì¶”ì¶œ í•¨ìˆ˜ ì •ì˜\n",
    "def classify_outcome(text):\n",
    "    \"\"\"íŒê²°ë¬¸ì—ì„œ ìŠ¹ì†Œ/íŒ¨ì†Œ ë¶„ë¥˜\"\"\"\n",
    "    win_keywords = ['ì¸ìš©', 'ìŠ¹ì†Œ', 'ë°›ì•„ë“¤ì¸ë‹¤', 'íƒ€ë‹¹í•˜ë‹¤', 'ì¸ì •ëœë‹¤']\n",
    "    lose_keywords = ['ê¸°ê°', 'íŒ¨ì†Œ', 'ë°›ì•„ë“¤ì´ì§€', #'ë¶€ë‹¹í•˜ë‹¤', \n",
    "                     'ì¸ì •ë˜ì§€']\n",
    "    \n",
    "    win_count = sum(1 for k in win_keywords if k in text)\n",
    "    lose_count = sum(1 for k in lose_keywords if k in text)\n",
    "    \n",
    "    if win_count > lose_count:\n",
    "        return 'win'\n",
    "    elif lose_count > win_count:\n",
    "        return 'lose'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "def extract_sentence_years(text):\n",
    "    \"\"\"í˜•ëŸ‰ ì¶”ì¶œ (ì˜ˆ: \"ì§•ì—­ 3ë…„\" â†’ 3)\"\"\"\n",
    "    pattern = r'ì§•ì—­\\s*(\\d+)ë…„'\n",
    "    match = re.search(pattern, text)\n",
    "    return int(match.group(1)) if match else 0\n",
    "\n",
    "def extract_fine(text):\n",
    "    \"\"\"ë²Œê¸ˆ ì¶”ì¶œ\"\"\"\n",
    "    patterns = [\n",
    "        (r'ë²Œê¸ˆ\\s*(\\d+)ì–µ', 100000000),\n",
    "        (r'ë²Œê¸ˆ\\s*(\\d+)ì²œë§Œ', 10000000),\n",
    "        (r'ë²Œê¸ˆ\\s*(\\d+)ë°±ë§Œ', 1000000),\n",
    "        (r'ë²Œê¸ˆ\\s*(\\d+)ë§Œ', 10000)\n",
    "    ]\n",
    "    \n",
    "    for pattern, multiplier in patterns:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            return int(match.group(1)) * multiplier\n",
    "    return 0\n",
    "\n",
    "def calculate_risk_score(text):\n",
    "    \"\"\"ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚° (0~100)\"\"\"\n",
    "    high_risk_keywords = ['ì§•ì—­', 'ì‹¤í˜•', 'êµ¬ì†', 'ë¬´ê¸°', 'ì‚¬í˜•']\n",
    "    medium_risk_keywords = ['ë²Œê¸ˆ', 'ê³¼íƒœë£Œ', 'ì†í•´ë°°ìƒ', 'ì²˜ë¶„']\n",
    "    \n",
    "    high_count = sum(2 for k in high_risk_keywords if k in text)\n",
    "    medium_count = sum(1 for k in medium_risk_keywords if k in text)\n",
    "    \n",
    "    score = min((high_count + medium_count) * 10, 100)\n",
    "    return score\n",
    "\n",
    "print(\"âœ… íŠ¹ì„± ì¶”ì¶œ í•¨ìˆ˜ 4ê°œ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c35f1be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ í•™ìŠµ ë°ì´í„°ì— ì¶”ê°€ íŠ¹ì„± ìƒì„± ì¤‘...\n",
      "  âœ“ ìŠ¹ì†Œ/íŒ¨ì†Œ ë ˆì´ë¸” ìƒì„±\n",
      "  âœ“ í˜•ëŸ‰ ì •ë³´ ì¶”ì¶œ\n",
      "  âœ“ ë²Œê¸ˆ ì •ë³´ ì¶”ì¶œ\n",
      "  âœ“ ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚°\n",
      "  âœ“ ìŠ¹ì†Œìœ¨ ë ˆì´ë¸” ìƒì„±\n",
      "\n",
      "âœ… ëª¨ë“  íŠ¹ì„± ìƒì„± ì™„ë£Œ!\n",
      "\n",
      "[ìƒì„±ëœ íŠ¹ì„± ìƒ˜í”Œ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>sentence_years</th>\n",
       "      <th>fine_amount</th>\n",
       "      <th>risk_score</th>\n",
       "      <th>win_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>lose</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>lose</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>lose</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    outcome  sentence_years  fine_amount  risk_score  win_rate\n",
       "78  unknown               0            0          10        50\n",
       "79     lose               0            0          10        20\n",
       "80     lose               0            0          10        20\n",
       "81     lose               0            0          10        20\n",
       "83  unknown               0            0          30        50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[íŠ¹ì„± í†µê³„]\n",
      "ìŠ¹ì†Œ ì‚¬ê±´: 465ê±´\n",
      "íŒ¨ì†Œ ì‚¬ê±´: 7,101ê±´\n",
      "ë¶ˆëª…í™•: 40,742ê±´\n",
      "í˜•ëŸ‰ ìˆëŠ” ì‚¬ê±´: 10,747ê±´\n",
      "ë²Œê¸ˆ ìˆëŠ” ì‚¬ê±´: 4,252ê±´\n"
     ]
    }
   ],
   "source": [
    "# ì…€4. ë°ì´í„°ì— ìƒˆ íŠ¹ì„± ì¶”ê°€\n",
    "print(\"\\nğŸ”„ í•™ìŠµ ë°ì´í„°ì— ì¶”ê°€ íŠ¹ì„± ìƒì„± ì¤‘...\")\n",
    "\n",
    "# 1) ìŠ¹ì†Œ/íŒ¨ì†Œ ë ˆì´ë¸”\n",
    "train_df['outcome'] = train_df['body'].apply(classify_outcome)\n",
    "test_df['outcome'] = test_df['body'].apply(classify_outcome)\n",
    "print(\"  âœ“ ìŠ¹ì†Œ/íŒ¨ì†Œ ë ˆì´ë¸” ìƒì„±\")\n",
    "\n",
    "# 2) í˜•ëŸ‰ ì •ë³´\n",
    "train_df['sentence_years'] = train_df['body'].apply(extract_sentence_years)\n",
    "test_df['sentence_years'] = test_df['body'].apply(extract_sentence_years)\n",
    "print(\"  âœ“ í˜•ëŸ‰ ì •ë³´ ì¶”ì¶œ\")\n",
    "\n",
    "# 3) ë²Œê¸ˆ ì •ë³´\n",
    "train_df['fine_amount'] = train_df['body'].apply(extract_fine)\n",
    "test_df['fine_amount'] = test_df['body'].apply(extract_fine)\n",
    "print(\"  âœ“ ë²Œê¸ˆ ì •ë³´ ì¶”ì¶œ\")\n",
    "\n",
    "# 4) ìœ„í—˜ë„ ì ìˆ˜\n",
    "train_df['risk_score'] = train_df['text'].apply(calculate_risk_score)\n",
    "test_df['risk_score'] = test_df['text'].apply(calculate_risk_score)\n",
    "print(\"  âœ“ ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚°\")\n",
    "\n",
    "# 5) ìŠ¹ì†Œìœ¨ ê³„ì‚° (outcome ê¸°ë°˜)\n",
    "outcome_map = {'win': 80, 'lose': 20, 'unknown': 50}\n",
    "train_df['win_rate'] = train_df['outcome'].map(outcome_map)\n",
    "test_df['win_rate'] = test_df['outcome'].map(outcome_map)\n",
    "print(\"  âœ“ ìŠ¹ì†Œìœ¨ ë ˆì´ë¸” ìƒì„±\")\n",
    "\n",
    "print(\"\\nâœ… ëª¨ë“  íŠ¹ì„± ìƒì„± ì™„ë£Œ!\")\n",
    "print(\"\\n[ìƒì„±ëœ íŠ¹ì„± ìƒ˜í”Œ]\")\n",
    "display(train_df[['outcome', 'sentence_years', 'fine_amount', 'risk_score', 'win_rate']].head())\n",
    "\n",
    "# í†µê³„ í™•ì¸\n",
    "print(\"\\n[íŠ¹ì„± í†µê³„]\")\n",
    "print(f\"ìŠ¹ì†Œ ì‚¬ê±´: {(train_df['outcome']=='win').sum():,}ê±´\")\n",
    "print(f\"íŒ¨ì†Œ ì‚¬ê±´: {(train_df['outcome']=='lose').sum():,}ê±´\")\n",
    "print(f\"ë¶ˆëª…í™•: {(train_df['outcome']=='unknown').sum():,}ê±´\")\n",
    "print(f\"í˜•ëŸ‰ ìˆëŠ” ì‚¬ê±´: {(train_df['sentence_years']>0).sum():,}ê±´\")\n",
    "print(f\"ë²Œê¸ˆ ìˆëŠ” ì‚¬ê±´: {(train_df['fine_amount']>0).sum():,}ê±´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f940e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LegalAIPredictor í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ì…€5. LegalAIPredictor í´ë˜ìŠ¤ ì •ì˜\n",
    "class LegalAIPredictor:\n",
    "    \"\"\"ë²•ë¥  AI ì¢…í•© ì˜ˆì¸¡ ëª¨ë¸\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.case_type_model = None\n",
    "        self.win_rate_model = None\n",
    "        self.sentence_model = None\n",
    "        self.risk_model = None\n",
    "        self.fine_model = None\n",
    "        self.vectorizer = None\n",
    "        \n",
    "    # def fit(self, X_text, y_case_type, y_win_rate, y_sentence, y_risk, y_fine):\n",
    "    def fit(self, X_text, y_win_rate, y_sentence, y_risk, y_fine): #ì†Œì†¡ë¶„ë¥˜ ì œê±°\n",
    "        \"\"\"ëª¨ë“  ëª¨ë¸ í•™ìŠµ\"\"\"\n",
    "        print(\"\\nğŸ”„ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\")\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸ ë²¡í„°í™” (ë‹¨ì–´ ê°œìˆ˜ë¥¼ 10,000ê°œë¡œ ì¡°ì •í•˜ì—¬ ì†ë„ ê·¹ëŒ€í™”)\n",
    "        self.vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2), min_df=5)\n",
    "        X_vec = self.vectorizer.fit_transform(X_text)\n",
    "        print(f\"  â†’ ë²¡í„°í™” ì™„ë£Œ! í¬ê¸°: {X_vec.shape}\")\n",
    "        \n",
    "        # # 1) ì†Œì†¡ ìœ í˜• ë¶„ë¥˜\n",
    "        # print(\"  1/5 ì†Œì†¡ ìœ í˜• ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "        # self.case_type_model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "        # self.case_type_model.fit(X_vec, y_case_type)\n",
    "        \n",
    "        # 2) ìŠ¹ì†Œìœ¨ ì˜ˆì¸¡ ëœë¤í¬ë ˆìŠ¤íŠ¸-> ë¦¿ì§€ë¡œ ë³€ê²½/í…ìŠ¤íŠ¸ì— ê°•í•˜ê³  ë¹ ë¦„.\n",
    "        # print(\"  2/5 ìŠ¹ì†Œìœ¨ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "        # self.win_rate_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        # self.win_rate_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "        # self.win_rate_model.fit(X_vec, y_win_rate)\n",
    "        print(\"  â†’ 2/5 ìŠ¹ì†Œìœ¨ ëª¨ë¸ í•™ìŠµ ì¤‘ (Ridge)...\")\n",
    "        self.win_rate_model = Ridge(alpha=1.0).fit(X_vec, y_win_rate)\n",
    "        \n",
    "        \n",
    "        # 3) í˜•ëŸ‰ ì˜ˆì¸¡\n",
    "        print(\"  3/5 í˜•ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "        # self.sentence_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        # self.sentence_model.fit(X_vec, y_sentence)\n",
    "        self.sentence_model = Ridge(alpha=1.0).fit(X_vec, y_sentence)\n",
    "        \n",
    "        # 4) ìœ„í—˜ë„ ì˜ˆì¸¡\n",
    "        print(\"  4/5 ìœ„í—˜ë„ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "        # self.risk_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        # self.risk_model.fit(X_vec, y_risk)\n",
    "        self.risk_model = Ridge(alpha=1.0).fit(X_vec, y_risk)\n",
    "        \n",
    "        # 5) ë²Œê¸ˆ ì˜ˆì¸¡\n",
    "        print(\"  5/5 ë²Œê¸ˆ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "        # self.fine_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        # self.fine_model.fit(X_vec, y_fine)\n",
    "        self.fine_model = Ridge(alpha=1.0).fit(X_vec, y_fine)\n",
    "        \n",
    "        print(\"âœ… ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "        return self\n",
    "    \n",
    "    def predict_all(self, text):\n",
    "        \"\"\"ëª¨ë“  ì˜ˆì¸¡ ìˆ˜í–‰\"\"\"\n",
    "        X_vec = self.vectorizer.transform([text])\n",
    "        \n",
    "        results = {\n",
    "            # 'case_type': self.case_type_model.predict(X_vec)[0], #ì†Œì†¡ë¶„ë¥˜\n",
    "            # 'case_type_proba': self.case_type_model.predict_proba(X_vec).max(), #ë¬´ìŠ¨ì†Œì†¡ì¸ì§€ í™•ë¥ \n",
    "            'win_rate': min(max(self.win_rate_model.predict(X_vec)[0], 0), 100),\n",
    "            'sentence_years': max(self.sentence_model.predict(X_vec)[0], 0),\n",
    "            'fine_amount': max(self.fine_model.predict(X_vec)[0], 0),\n",
    "            'risk_score': min(max(self.risk_model.predict(X_vec)[0], 0), 100)\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "\n",
    "print(\"âœ… LegalAIPredictor í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6253fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ ëª¨ë¸ í•™ìŠµ ì‹œì‘..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  â†’ ë²¡í„°í™” ì™„ë£Œ! í¬ê¸°: (48308, 10000)\n",
      "  â†’ 2/5 ìŠ¹ì†Œìœ¨ ëª¨ë¸ í•™ìŠµ ì¤‘ (Ridge)...\n",
      "  3/5 í˜•ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ì¤‘...\n",
      "  4/5 ìœ„í—˜ë„ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ì¤‘...\n",
      "  5/5 ë²Œê¸ˆ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ì¤‘...\n",
      "âœ… ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ê²°ê³¼\n",
      "============================================================\n",
      "\n",
      "ì „ì²´ 5,435ê±´ ì˜ˆì¸¡ ì¤‘...\n",
      "  ì§„í–‰: 1,000/5,435\n",
      "  ì§„í–‰: 2,000/5,435\n",
      "  ì§„í–‰: 3,000/5,435\n",
      "  ì§„í–‰: 4,000/5,435\n",
      "  ì§„í–‰: 5,000/5,435\n",
      "\n",
      "[ì˜ˆì¸¡ ê²°ê³¼ í†µê³„]\n",
      "í‰ê·  ìŠ¹ì†Œìœ¨: 45.4%\n",
      "í‰ê·  í˜•ëŸ‰: 0.48ë…„\n",
      "í‰ê·  ë²Œê¸ˆ: 33,394,420ì›\n",
      "í‰ê·  ìœ„í—˜ë„: 12.9/100\n",
      "\n",
      "[ì‹¤ì œê°’ í†µê³„]\n",
      "ì‹¤ì œ í‰ê·  ìŠ¹ì†Œìœ¨: 45.4%\n",
      "ì‹¤ì œ í‰ê·  í˜•ëŸ‰: 0.37ë…„\n",
      "ì‹¤ì œ í‰ê·  ë²Œê¸ˆ: 513,358ì›\n",
      "ì‹¤ì œ í‰ê·  ìœ„í—˜ë„: 12.6/100\n"
     ]
    }
   ],
   "source": [
    "# ì…€6. ëª¨ë¸í•™ìŠµ\n",
    "# í•™ìŠµë°ì´í„° ì¤€ë¹„\n",
    "X_train = train_df['text'] #ì‚¬ê±´ë‚´ìš©\n",
    "# y_case_type = train_df['case_type'] #ì†Œì†¡ë¶„ë¥˜\n",
    "y_win_rate = train_df['win_rate'] #ìŠ¹ì†Œìœ¨\n",
    "y_sentence = train_df['sentence_years'] #í˜•ëŸ‰ì˜ˆì¸¡\n",
    "y_risk = train_df['risk_score'] #ìœ„í—˜ë„\n",
    "y_fine = train_df['fine_amount'] #ë²Œê¸ˆ\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™” ë° í•™ìŠµ\n",
    "predictor = LegalAIPredictor()\n",
    "# predictor.fit(X_train, #y_case_type,\n",
    "#               y_win_rate, y_sentence, y_risk, y_fine)\n",
    "predictor.fit(X_train, y_win_rate, y_sentence, y_risk, y_fine)\n",
    "\n",
    "# %% [ì…€ 7: ì„±ëŠ¥ í‰ê°€]\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ê²°ê³¼\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì˜ˆì¸¡ (ì „ì²´ ë°ì´í„°)\n",
    "test_predictions = []\n",
    "print(f\"\\nì „ì²´ {len(test_df):,}ê±´ ì˜ˆì¸¡ ì¤‘...\")\n",
    "\n",
    "for idx, text in enumerate(test_df['text'], 1):\n",
    "    if idx % 1000 == 0:\n",
    "        print(f\"  ì§„í–‰: {idx:,}/{len(test_df):,}\")\n",
    "    pred = predictor.predict_all(text)\n",
    "    test_predictions.append(pred)\n",
    "\n",
    "# ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "pred_df = pd.DataFrame(test_predictions)\n",
    "\n",
    "print(\"\\n[ì˜ˆì¸¡ ê²°ê³¼ í†µê³„]\")\n",
    "print(f\"í‰ê·  ìŠ¹ì†Œìœ¨: {pred_df['win_rate'].mean():.1f}%\")\n",
    "print(f\"í‰ê·  í˜•ëŸ‰: {pred_df['sentence_years'].mean():.2f}ë…„\")\n",
    "print(f\"í‰ê·  ë²Œê¸ˆ: {pred_df['fine_amount'].mean():,.0f}ì›\")\n",
    "print(f\"í‰ê·  ìœ„í—˜ë„: {pred_df['risk_score'].mean():.1f}/100\")\n",
    "\n",
    "# ì‹¤ì œê°’ê³¼ ë¹„êµ\n",
    "print(\"\\n[ì‹¤ì œê°’ í†µê³„]\")\n",
    "print(f\"ì‹¤ì œ í‰ê·  ìŠ¹ì†Œìœ¨: {test_df['win_rate'].mean():.1f}%\")\n",
    "print(f\"ì‹¤ì œ í‰ê·  í˜•ëŸ‰: {test_df['sentence_years'].mean():.2f}ë…„\")\n",
    "print(f\"ì‹¤ì œ í‰ê·  ë²Œê¸ˆ: {test_df['fine_amount'].mean():,.0f}ì›\")\n",
    "print(f\"ì‹¤ì œ í‰ê·  ìœ„í—˜ë„: {test_df['risk_score'].mean():.1f}/100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f74b9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 1: í˜•ì‚¬ ì‚¬ê±´\n",
      "\n",
      "============================================================\n",
      "ğŸ¤– AI ë²•ë¥  ìƒë‹´ ê²°ê³¼\n",
      "============================================================\n",
      "ğŸ“Š ì˜ˆìƒ ìŠ¹ì†Œìœ¨: 47.7%\n",
      "âš ï¸ ìœ„í—˜ë„: 6.8/100\n",
      "\n",
      "âœ… ë‚®ì€ ìœ„í—˜: ê¸°ë³¸ì ì¸ ë²•ë¥  ì ˆì°¨ë¡œ ëŒ€ì‘ ê°€ëŠ¥í•  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\n",
      "============================================================\n",
      "\n",
      "ğŸ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 2: ë¯¼ì‚¬ ì‚¬ê±´\n",
      "\n",
      "============================================================\n",
      "ğŸ¤– AI ë²•ë¥  ìƒë‹´ ê²°ê³¼\n",
      "============================================================\n",
      "ğŸ“Š ì˜ˆìƒ ìŠ¹ì†Œìœ¨: 43.9%\n",
      "âš ï¸ ìœ„í—˜ë„: 5.0/100\n",
      "\n",
      "âœ… ë‚®ì€ ìœ„í—˜: ê¸°ë³¸ì ì¸ ë²•ë¥  ì ˆì°¨ë¡œ ëŒ€ì‘ ê°€ëŠ¥í•  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\n",
      "============================================================\n",
      "\n",
      "ğŸ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 3: í–‰ì • ì‚¬ê±´\n",
      "\n",
      "============================================================\n",
      "ğŸ¤– AI ë²•ë¥  ìƒë‹´ ê²°ê³¼\n",
      "============================================================\n",
      "ğŸ“Š ì˜ˆìƒ ìŠ¹ì†Œìœ¨: 49.8%\n",
      "âš ï¸ ìœ„í—˜ë„: 15.0/100\n",
      "\n",
      "âœ… ë‚®ì€ ìœ„í—˜: ê¸°ë³¸ì ì¸ ë²•ë¥  ì ˆì°¨ë¡œ ëŒ€ì‘ ê°€ëŠ¥í•  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'win_rate': np.float64(49.84724613361678),\n",
       " 'sentence_years': 0,\n",
       " 'fine_amount': 0,\n",
       " 'risk_score': np.float64(14.970771008803984)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì…€8. analyze_case í•¨ìˆ˜\n",
    "\n",
    "def analyze_case(user_input):\n",
    "    \"\"\"ì‚¬ìš©ì ì…ë ¥ ë¶„ì„\"\"\"\n",
    "    result = predictor.predict_all(user_input)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ¤– AI ë²•ë¥  ìƒë‹´ ê²°ê³¼\")\n",
    "    print(\"=\"*60)\n",
    "    # print(f\"\\nğŸ“ ì†Œì†¡ ìœ í˜•: {result['case_type']} (í™•ì‹ ë„: {result['case_type_proba']:.1%})\")\n",
    "    print(f\"ğŸ“Š ì˜ˆìƒ ìŠ¹ì†Œìœ¨: {result['win_rate']:.1f}%\")\n",
    "    \n",
    "    if result['sentence_years'] > 0:\n",
    "        print(f\"âš–ï¸ ì˜ˆìƒ í˜•ëŸ‰: {result['sentence_years']:.1f}ë…„\")\n",
    "    \n",
    "    if result['fine_amount'] > 0:\n",
    "        print(f\"ğŸ’° ì˜ˆìƒ ë²Œê¸ˆ: {result['fine_amount']:,.0f}ì›\")\n",
    "    \n",
    "    print(f\"âš ï¸ ìœ„í—˜ë„: {result['risk_score']:.1f}/100\")\n",
    "    \n",
    "    # ìœ„í—˜ë„ì— ë”°ë¥¸ ì¡°ì–¸\n",
    "    if result['risk_score'] >= 70:\n",
    "        print(\"\\nâ›” ë†’ì€ ìœ„í—˜: ì „ë¬¸ ë³€í˜¸ì‚¬ ìƒë‹´ì„ ê°•ë ¥íˆ ê¶Œì¥í•©ë‹ˆë‹¤.\")\n",
    "    elif result['risk_score'] >= 40:\n",
    "        print(\"\\nâš ï¸ ì¤‘ê°„ ìœ„í—˜: ë²•ë¥  ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì‹œëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(\"\\nâœ… ë‚®ì€ ìœ„í—˜: ê¸°ë³¸ì ì¸ ë²•ë¥  ì ˆì°¨ë¡œ ëŒ€ì‘ ê°€ëŠ¥í•  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤\n",
    "print(\"\\nğŸ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 1: í˜•ì‚¬ ì‚¬ê±´\")\n",
    "analyze_case(\"ìƒëŒ€ë°©ì´ ë‚˜ë¥¼ ë°€ì–´ì„œ ë‚˜ëŠ” ì „ì¹˜ 4ì£¼ì˜ ì§„ë‹¨ì„ ë°›ì•˜ë‹¤.\")\n",
    "\n",
    "print(\"\\nğŸ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 2: ë¯¼ì‚¬ ì‚¬ê±´\")\n",
    "analyze_case(\"ì„ëŒ€ì¸ì´ ë³´ì¦ê¸ˆ 1000ë§Œì›ì„ ì €ì—ê²Œ ëŒë ¤ì£¼ì§€ ì•Šì•„ ì„ì°¨ê¶Œ ë“±ê¸°ëª…ë ¹ì„ ì‹ ì²­í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"\\nğŸ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 3: í–‰ì • ì‚¬ê±´\")\n",
    "analyze_case(\"í–‰ì •ì²­ì˜ ì˜ì—…ì •ì§€ 6ê°œì›” ì²˜ë¶„ì´ ë¶€ë‹¹í•˜ë¯€ë¡œ ì´ë¥¼ ì·¨ì†Œí•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "791314a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ì…€9. CaseFinder í´ë˜ìŠ¤\n",
    "\n",
    "# class CaseFinder:\n",
    "#     \"\"\"ìœ ì‚¬ íŒë¡€ ê²€ìƒ‰\"\"\"\n",
    "    \n",
    "#     def __init__(self, vectorizer, case_db):\n",
    "#         self.vectorizer = vectorizer\n",
    "#         self.case_db = case_db\n",
    "#         print(\"  â†’ íŒë¡€ ë²¡í„°í™” ì¤‘...\")\n",
    "#         self.case_vectors = vectorizer.transform(case_db['text'])\n",
    "#         print(f\"    ì´ {len(case_db):,}ê°œ íŒë¡€ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "        \n",
    "#     def find_similar_cases(self, query_text, top_k=5):\n",
    "#         \"\"\"ìœ ì‚¬í•œ íŒë¡€ ì°¾ê¸°\"\"\"\n",
    "#         query_vec = self.vectorizer.transform([query_text])\n",
    "#         similarities = cosine_similarity(query_vec, self.case_vectors)[0]\n",
    "        \n",
    "#         top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "        \n",
    "#         results = []\n",
    "#         for idx in top_indices:\n",
    "#             results.append({\n",
    "#                 'case_name': self.case_db.iloc[idx]['case_name'],\n",
    "#                 'case_num': self.case_db.iloc[idx]['case_num'],\n",
    "#                 'similarity': similarities[idx],\n",
    "#                 'summary': self.case_db.iloc[idx]['body'][:200] + \"...\"\n",
    "#             })\n",
    "        \n",
    "#         return results\n",
    "\n",
    "# # íŒë¡€ ê²€ìƒ‰ê¸° ì´ˆê¸°í™”\n",
    "# print(\"\\nğŸ” íŒë¡€ ê²€ìƒ‰ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...\")\n",
    "# case_finder = CaseFinder(predictor.vectorizer, train_df)\n",
    "# print(\"âœ… íŒë¡€ ê²€ìƒ‰ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "\n",
    "# # # í…ŒìŠ¤íŠ¸\n",
    "# # print(\"\\n\" + \"=\"*60)\n",
    "# # print(\"ğŸ” ìœ ì‚¬ íŒë¡€ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\")\n",
    "# # print(\"=\"*60)\n",
    "# # user_query = \"ì„ëŒ€ì¸ì´ ë³´ì¦ê¸ˆì„ ëŒë ¤ì£¼ì§€ ì•ŠìŠµë‹ˆë‹¤.\"\n",
    "# # similar_cases = case_finder.find_similar_cases(user_query, top_k=3)\n",
    "\n",
    "# # print(f\"\\nğŸ“ ì…ë ¥: {user_query}\")\n",
    "# # print(\"\\n[ìœ ì‚¬ íŒë¡€ Top 3]\")\n",
    "# # for i, case in enumerate(similar_cases, 1):\n",
    "# #     print(f\"\\n{i}. {case['case_name']}\")\n",
    "# #     print(f\"   ì‚¬ê±´ë²ˆí˜¸: {case['case_num']}\")\n",
    "# #     print(f\"   ìœ ì‚¬ë„: {case['similarity']:.2%}\")\n",
    "# #     print(f\"   ìš”ì•½: {case['summary']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32eb1b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: ../pkl_file/machine_data/model/legal_ai_machinModel.pkl\n",
      "âœ… ê°•í™”ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ì…€10. ëª¨ë¸ ì €ì¥\n",
    "\n",
    "# ì „ì²´ ëª¨ë¸ ì €ì¥\n",
    "joblib.dump(predictor, '../pkl_file/machine_data/model/legal_ai_machinModel.pkl')\n",
    "print(\"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: ../pkl_file/machine_data/model/legal_ai_machinModel.pkl\")\n",
    "\n",
    "# # íŒë¡€ ê²€ìƒ‰ê¸°ë„ ì €ì¥\n",
    "# joblib.dump(case_finder, '../pkl_file/machine_data/case_finderMachinModel.pkl')\n",
    "# print(\"âœ… íŒë¡€ ê²€ìƒ‰ê¸° ì €ì¥ ì™„ë£Œ: ../pkl_file/machine_data/case_finderMachinModel.pkl\")\n",
    "\n",
    "# ì—…ë°ì´íŠ¸ëœ ë°ì´í„°í”„ë ˆì„ë„ ì €ì¥\n",
    "train_df.to_pickle(\"../pkl_file/machine_data/train_machineData.pkl\")\n",
    "test_df.to_pickle(\"../pkl_file/machine_data/test_machineData.pkl\")\n",
    "print(\"âœ… ê°•í™”ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3191d360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ›ï¸ AI ë²•ë¥  ì¢…í•© ë¶„ì„ ì‹œìŠ¤í…œ\n",
      "======================================================================\n",
      "\n",
      "ğŸ“ ì…ë ¥ ë‚´ìš©:\n",
      "\n",
      "ì €ëŠ” íšŒì‚¬ì—ì„œ ë¶€ë‹¹í•´ê³ ë¥¼ ë‹¹í–ˆìŠµë‹ˆë‹¤.\n",
      "ì •ë‹¹í•œ ì‚¬ìœ  ì—†ì´ ê°‘ìê¸° í•´ê³  í†µë³´ë¥¼ ë°›ì•˜ê³ ,\n",
      "í‡´ì§ê¸ˆ 500ë§Œì›ë„ ì œëŒ€ë¡œ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n",
      "ê·¼ë¬´ ê¸°ê°„ì€ 3ë…„ì…ë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š ë¶„ì„ ê²°ê³¼\n",
      "======================================================================\n",
      "ğŸ“Š ì˜ˆìƒ ìŠ¹ì†Œìœ¨: 48.1%\n",
      "ğŸ’° ì˜ˆìƒ ë²Œê¸ˆ: 72,707,900ì›\n",
      "âš ï¸ ìœ„í—˜ë„: 2.0/100\n",
      "\n",
      "======================================================================\n",
      "AI ë²•ë¥ ì„œë¹„ìŠ¤ì˜ ì˜ê²¬ *ì°¸ê³ ìš©ìœ¼ë¡œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\n",
      "======================================================================\n",
      "\n",
      "âœ… ìœ„í—˜ë„ : ë¹„êµì  ë‚®ìŒ\n",
      "  - ê¸°ë³¸ì ì¸ ë²•ë¥  ì ˆì°¨ë¡œ ëŒ€ì‘ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
      "  - ê´€ë ¨ ë²•ë¥ ì„ ìˆ™ì§€í•˜ì‹œë©´ ë„ì›€ì´ ë©ë‹ˆë‹¤.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'win_rate': np.float64(48.08365126384487),\n",
       " 'sentence_years': 0,\n",
       " 'fine_amount': np.float64(72707900.18688074),\n",
       " 'risk_score': np.float64(1.9798581252768666)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì…€ 11. ìµœì¢… í†µí•© í•¨ìˆ˜\n",
    "\n",
    "def full_legal_analysis(user_input):\n",
    "    # \"\"\"ì™„ì „í•œ ë²•ë¥  ë¶„ì„ (ì˜ˆì¸¡ + íŒë¡€ ê²€ìƒ‰)\"\"\"\n",
    "    \"\"\"ì™„ì „í•œ ë²•ë¥  ë¶„ì„ (ì˜ˆì¸¡)\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ›ï¸ AI ë²•ë¥  ì¢…í•© ë¶„ì„ ì‹œìŠ¤í…œ\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nğŸ“ ì…ë ¥ ë‚´ìš©:\\n{user_input}\\n\")\n",
    "    \n",
    "    # 1. ì˜ˆì¸¡\n",
    "    result = predictor.predict_all(user_input)\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"ğŸ“Š ë¶„ì„ ê²°ê³¼\")\n",
    "    print(\"=\"*70)\n",
    "    # print(f\"\\nğŸ“ ì†Œì†¡ ìœ í˜•: {result['case_type']} (í™•ì‹ ë„: {result['case_type_proba']:.1%})\")\n",
    "    print(f\"ğŸ“Š ì˜ˆìƒ ìŠ¹ì†Œìœ¨: {result['win_rate']:.1f}%\")\n",
    "    \n",
    "    if result['sentence_years'] > 0:\n",
    "        print(f\"âš–ï¸ ì˜ˆìƒ í˜•ëŸ‰: {result['sentence_years']:.1f}ë…„\")\n",
    "    \n",
    "    if result['fine_amount'] > 0:\n",
    "        print(f\"ğŸ’° ì˜ˆìƒ ë²Œê¸ˆ: {result['fine_amount']:,.0f}ì›\")\n",
    "    \n",
    "    print(f\"âš ï¸ ìœ„í—˜ë„: {result['risk_score']:.1f}/100\")\n",
    "    \n",
    "    # # 2. ìœ ì‚¬ íŒë¡€ ê²€ìƒ‰\n",
    "    # similar_cases = case_finder.find_similar_cases(user_input, top_k=3)\n",
    "    \n",
    "    # print(\"\\n\" + \"=\"*70)\n",
    "    # print(\"ğŸ“š ê´€ë ¨ íŒë¡€\")\n",
    "    # print(\"=\"*70)\n",
    "    # for i, case in enumerate(similar_cases, 1):\n",
    "    #     print(f\"\\n{i}. {case['case_name']}\")\n",
    "    #     print(f\"   ì‚¬ê±´ë²ˆí˜¸: {case['case_num']}\")\n",
    "    #     print(f\"   ìœ ì‚¬ë„: {case['similarity']:.2%}\")\n",
    "    \n",
    "    # 3. ìœ„í—˜ë„ ë¶„ì„ ë° ì¡°ì–¸\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"AI ë²•ë¥ ì„œë¹„ìŠ¤ì˜ ì˜ê²¬ *ì°¸ê³ ìš©ìœ¼ë¡œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if result['risk_score'] >= 70:\n",
    "        print(\"\\nâ›” ìœ„í—˜ë„ : ë†’ìŒ\")\n",
    "        print(\"  - ì¦‰ì‹œ ì „ë¬¸ ë³€í˜¸ì‚¬ ìƒë‹´ì„ ë°›ìœ¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\")\n",
    "        print(\"  - ì¦ê±° ìë£Œë¥¼ ì² ì €íˆ ì¤€ë¹„í•˜ì„¸ìš”.\")\n",
    "    elif result['risk_score'] >= 40:\n",
    "        print(\"\\nâš ï¸ ìœ„í—˜ë„ : ì¤‘ê°„\")\n",
    "        print(\"  - ë²•ë¥  ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì‹œëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"  - ê´€ë ¨ ì„œë¥˜ë¥¼ ë¯¸ë¦¬ ì¤€ë¹„í•˜ì„¸ìš”.\")\n",
    "    else:\n",
    "        print(\"\\nâœ… ìœ„í—˜ë„ : ë¹„êµì  ë‚®ìŒ\")\n",
    "        print(\"  - ê¸°ë³¸ì ì¸ ë²•ë¥  ì ˆì°¨ë¡œ ëŒ€ì‘ ê°€ëŠ¥í•©ë‹ˆë‹¤.\")\n",
    "        print(\"  - ê´€ë ¨ ë²•ë¥ ì„ ìˆ™ì§€í•˜ì‹œë©´ ë„ì›€ì´ ë©ë‹ˆë‹¤.\")    \n",
    "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return result #, similar_cases\n",
    "\n",
    "\n",
    "\n",
    "# ìµœì¢… í…ŒìŠ¤íŠ¸\n",
    "test_input = \"\"\"\n",
    "ì €ëŠ” íšŒì‚¬ì—ì„œ ë¶€ë‹¹í•´ê³ ë¥¼ ë‹¹í–ˆìŠµë‹ˆë‹¤.\n",
    "ì •ë‹¹í•œ ì‚¬ìœ  ì—†ì´ ê°‘ìê¸° í•´ê³  í†µë³´ë¥¼ ë°›ì•˜ê³ ,\n",
    "í‡´ì§ê¸ˆ 500ë§Œì›ë„ ì œëŒ€ë¡œ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n",
    "ê·¼ë¬´ ê¸°ê°„ì€ 3ë…„ì…ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "full_legal_analysis(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ae77d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ‰ ë¨¸ì‹ ëŸ¬ë‹ íŒŒíŠ¸ ì—…ê·¸ë ˆì´ë“œ ì™„ë£Œ!\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Œ êµ¬í˜„ëœ ê¸°ëŠ¥:\n",
      "  âœ…  ìŠ¹ì†Œìœ¨ ì˜ˆì¸¡\n",
      "  âœ…  í˜•ëŸ‰ ì˜ˆì¸¡\n",
      "  âœ…  ë²Œê¸ˆ ì˜ˆì¸¡\n",
      "  âœ…  ìœ„í—˜ë„ ë¶„ì„\n",
      "\n",
      "ğŸ“¦ ì €ì¥ëœ íŒŒì¼:\n",
      "  - ../pkl_file/machine_data/model/legal_ai_machinModel.pkl\n",
      "  - ../pkl_file/machine_data/train_machineData.pkl\n",
      "  - ../pkl_file/machine_data/test_machineData.pkl\n",
      "\n",
      "ğŸ”œ ë‹¤ìŒ ë‹¨ê³„: ë”¥ëŸ¬ë‹ ëª¨ë¸ ê°œë°œ (BERT í™œìš©)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ì…€ 12 ì™„ë£Œ ë©”ì‹œì§€\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ‰ ë¨¸ì‹ ëŸ¬ë‹ íŒŒíŠ¸ ì—…ê·¸ë ˆì´ë“œ ì™„ë£Œ!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nğŸ“Œ êµ¬í˜„ëœ ê¸°ëŠ¥:\")\n",
    "# print(\"  âœ… 1. ì†Œì†¡ ìœ í˜• ë¶„ë¥˜\")\n",
    "print(\"  âœ…  ìŠ¹ì†Œìœ¨ ì˜ˆì¸¡\")\n",
    "print(\"  âœ…  í˜•ëŸ‰ ì˜ˆì¸¡\")\n",
    "print(\"  âœ…  ë²Œê¸ˆ ì˜ˆì¸¡\")\n",
    "print(\"  âœ…  ìœ„í—˜ë„ ë¶„ì„\")\n",
    "# print(\"  âœ…  ìœ ì‚¬ íŒë¡€ ê²€ìƒ‰\")\n",
    "print(\"\\nğŸ“¦ ì €ì¥ëœ íŒŒì¼:\")\n",
    "\n",
    "print(\"  - ../pkl_file/machine_data/model/legal_ai_machinModel.pkl\")\n",
    "# print(\"  - ../pkl_file/machine_data/case_finderMachinModel.pk\") #íŒë¡€ ê²€ìƒ‰ê¸°\n",
    "print(\"  - ../pkl_file/machine_data/train_machineData.pkl\")\n",
    "print(\"  - ../pkl_file/machine_data/test_machineData.pkl\")\n",
    "print(\"\\nğŸ”œ ë‹¤ìŒ ë‹¨ê³„: ë”¥ëŸ¬ë‹ ëª¨ë¸ ê°œë°œ (BERT í™œìš©)\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
